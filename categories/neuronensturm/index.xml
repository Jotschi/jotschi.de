<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Neuronensturm on Jotschi&#39;s Blog</title>
    <link>http://jotschi.de/categories/neuronensturm/</link>
    <description>Recent content in Neuronensturm on Jotschi&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Sep 2011 21:10:34 +0000</lastBuildDate>
    <atom:link href="http://jotschi.de/categories/neuronensturm/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>JavaCPP Examples</title>
      <link>http://jotschi.de/2011/09/23/javacpp-examples/</link>
      <pubDate>Fri, 23 Sep 2011 21:10:34 +0000</pubDate>
      
      <guid>http://jotschi.de/2011/09/23/javacpp-examples/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;I finally found the time to write post about the javacpp &amp;lt;a href=&#34;https://github.com/Jotschi/javacpp-examples&#34;&amp;gt;examples&amp;lt;/a&amp;gt; i created since i wanted to explore the capabilities of the &amp;lt;a href=&#34;http://code.google.com/p/javacpp/&#34;&amp;gt;JavaCPP library&amp;lt;/a&amp;gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;Please note that the examples are only tested under linux and probably won&amp;#8217;t run on windows/mac.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The examples can be fetched from my &lt;a href=&#34;https://github.com/Jotschi/javacpp-examples&#34;&gt;github repository&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;So far i created four different examples. Each for a specific usecase:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_javacpp_sharedlib_example&#34;&gt;javacpp-sharedlib-example&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This example shows how to use a own cpp shared library with the library.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The example consists of multiple pieces that finally work together.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;1. Cube.cpp&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The shared lib will be created from the Cube cpp class.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;highlight&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;#include &#34;Cube.h&#34;

void Cube::setSide(double s) {
	side = s &amp;lt;= 0 ? 1 : s;
}

double Cube::getSide() {
	return side;
}

double Cube::getArea() {
	return 6 * side * side;
}

double Cube::getVolume() {
	return side * side * side;
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Cube.h&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;highlight&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;#ifndef CUBE_H
#define CUBE_H

class Cube {
	private:
		double side;
	public:
		Cube() {};
		~Cube() {};

		// copy constructor
		Cube(class Cube&amp;amp; cube) {
			side = cube.side;
		}

		void setSide(double s);
		double getSide();
		double getArea();
		double getVolume();
};

#endif&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_2_javacube_java&#34;&gt;2. JavaCube.java&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The JavaCube java class acts as a wrapper/glue that fits between the gap of java and native code. Normally you would here defined your jni hooks which then would be implemented. Since i use JavaCPP this step is radically simplified. The annotations are used to give javacpp all the information it needs to prepare its g++ command that in the final compile step will create the library that can be shipped with the java program.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;highlight&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;package de.jotschi.javacpp.example;
import static com.googlecode.javacpp.Loader.load;

import com.googlecode.javacpp.Pointer;
import com.googlecode.javacpp.annotation.Name;
import com.googlecode.javacpp.annotation.Platform;

@Platform(include = &#34;Cube.h&#34;, link = &#34;Cube&#34;)
public class JavaCube {

	NativeCube cube;
	static {
		load();
	}

	public JavaCube() {
		cube = new NativeCube();
	}

	public void setSide(double s) {
		cube.setSide(s);

	}

	public double getArea() {
		return cube.getArea();
	}

	public double getSide() {
		return cube.getSide();
	}

	public double getVolume() {
		return cube.getVolume();
	}

	@Name(&#34;Cube&#34;)
	public static class NativeCube extends Pointer {

		static {
			load();
		}

		public NativeCube() {
			allocate();
		}

		public NativeCube(Pointer p) {
			super(p);
		}

		public native void setSide(double s);

		// this = new Cube()
		private native void allocate();

		private native double getArea();

		private native double getSide();

		private native double getVolume();

	}
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Once the java files have been compiled the exec-maven-plugin will be executed which itself executes the makefile that builds the shared library.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;highlight&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&amp;lt;execution&amp;gt;
	&amp;lt;id&amp;gt;build-sharedlib&amp;lt;/id&amp;gt;
	&amp;lt;phase&amp;gt;process-classes&amp;lt;/phase&amp;gt;
	&amp;lt;goals&amp;gt;
		&amp;lt;goal&amp;gt;exec&amp;lt;/goal&amp;gt;
	&amp;lt;/goals&amp;gt;
	&amp;lt;configuration&amp;gt;
		&amp;lt;executable&amp;gt;make&amp;lt;/executable&amp;gt;
		&amp;lt;commandlineArgs&amp;gt;main&amp;lt;/commandlineArgs&amp;gt;
		&amp;lt;workingDirectory&amp;gt;${basedir}/src/main/jni&amp;lt;/workingDirectory&amp;gt;
	&amp;lt;/configuration&amp;gt;
&amp;lt;/execution&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This library will be used within the next execution of the exec-maven-plugin. This final execution step will invoke the javacpp builder which generated the jni headers from the java class annotations and it also compiles the jni header interface against the previously created library.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;listingblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;pre class=&#34;highlight&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&amp;lt;execution&amp;gt;
	&amp;lt;id&amp;gt;build-jnilib&amp;lt;/id&amp;gt;
	&amp;lt;phase&amp;gt;process-classes&amp;lt;/phase&amp;gt;
	&amp;lt;goals&amp;gt;
		&amp;lt;goal&amp;gt;exec&amp;lt;/goal&amp;gt;
	&amp;lt;/goals&amp;gt;
	&amp;lt;configuration&amp;gt;
		&amp;lt;executable&amp;gt;java&amp;lt;/executable&amp;gt;
		&amp;lt;commandlineArgs&amp;gt;-jar ../libs/javacpp.jar -Dcompiler.linkpath=${basedir}/target/classes/linux-x86 -Dcompiler.includepath=${basedir}/src/main/jni -classpath target/classes de.jotschi.javacpp.example.JavaCube&amp;lt;/commandlineArgs&amp;gt;
	&amp;lt;/configuration&amp;gt;
&amp;lt;/execution&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The CubeTest.java Junit tests shows how the created java class that wraps the native class works.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_javacpp_libc6_example_javacpp_stdlib_example&#34;&gt;javacpp-libc6-example / javacpp-stdlib-example&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;These examples are very similar to the javacpp-sharedlib-example. The libc6 example show how to use JavaCPP with the libc6 library and c code. The stdlib example on the other hand uses the c++ stdlib.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_javacpp_android_example&#34;&gt;javacpp-android-example&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;This example shows how to use a android maven project in combination with JavaCPP. The example shows how to mix java with native code. The java part creates a opengl surface and the native code is used to execute a opengl function that changed the color of the display.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Removal of Humans In Motion Pictures</title>
      <link>http://jotschi.de/2009/01/04/removal-of-humans-in-motion-pictures/</link>
      <pubDate>Sun, 04 Jan 2009 00:16:18 +0000</pubDate>
      
      <guid>http://jotschi.de/2009/01/04/removal-of-humans-in-motion-pictures/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;What do we need to remove a person from a video source?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;At first we have to identify the person in the video. This could be done by using face tracking.
{% youtube 5sPh6-J9wOA %}&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Once the location of a face of a moving person is identified within the video source we can outline the persons body. The outline of the person can be estimated by analyzing the optical flow of the video source. The corresponding pixels of the head that was pinpointed by using face tracking will most likely move with the same direction and speed as the pixels from other body parts. The background of the person can be used as a static plane by analyzing the camera movements. Once the background has been defined an estimation of the persons outline is more reliable because in the most cases the motion and direction of the background pixels and the motion and direction of the persons pixels vary.
Moreover it is also possible to use depth estimation of the image to extrapolate different layers of the image that could be assigned to the person or the background to support the identification of the persons pixels.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Once the person has been identified the person can be removed and the gap can be filled by using texture synthesis.
{% youtube fWwy2gZuD6E %}&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Harry Shum - Microsoft Research Asia&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;In fact is is also possible to fill the gap of the person by using pixel areas from subsequent frames were no person was covering the same area. This approach is illustrated here:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://www.vision.huji.ac.il/demos/removal/removal.html&#34; class=&#34;bare&#34;&gt;http://www.vision.huji.ac.il/demos/removal/removal.html&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Multitouch Userinterface with WiiMote</title>
      <link>http://jotschi.de/2008/01/28/multitouch-userinterface-with-wiimote/</link>
      <pubDate>Mon, 28 Jan 2008 02:11:11 +0000</pubDate>
      
      <guid>http://jotschi.de/2008/01/28/multitouch-userinterface-with-wiimote/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Using the WiiMote you can create a multitouch userinterface. Johnny Chung Lee, Carnegie Mellon University demonstrate this in one of his videos:&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;a id=&#34;more&#34;&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;a id=&#34;more-108&#34;&amp;gt;&amp;lt;/a&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&amp;lt;embed src=&#34;http://www.youtube.com/v/5s5EvhHy7eQ&amp;amp;rel=1&#34; type=&#34;application/x-shockwave-flash&#34; wmode=&#34;transparent&#34; height=&#34;355&#34; width=&#34;425&#34;&amp;gt;&amp;lt;/embed&amp;gt;&amp;lt;/p&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;He uses a lightpen with a build in infrared LED to get a tracking point for the wiimote infrared camera.I think it is possible to build a touchpad/touchtable where you don&amp;#8217;t need any pen to interact with the userinterface.Touching the upper layer of the touchpad will lower the layer section in this place and cross the directional lightbeams which are arranged underneath the touchpad. Therefor the place where the touchpad was touched is marked with IR light and can be tracked by the wii controler which is placed under the touchpad area. The infrared camera points to the touchpad and &#39;sees&#39; the places where the material crosses the lightbeams. The video illustrates this process.&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;&amp;lt;embed src=&#34;http://www.youtube.com/v/YUGGAuENsZA&amp;amp;rel=1&#34; type=&#34;application/x-shockwave-flash&#34; wmode=&#34;transparent&#34; height=&#34;355&#34; width=&#34;425&#34;&amp;gt;&amp;lt;/embed&amp;gt;&amp;lt;/p&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Another way to detect touched areas on the touchpad might work with a special material of the upper layer. The top of the touchpad layer can be anything you like but the bottom layer should be something reflective. When you point an infrared lightsource to this reflective material the light will bounce off to another direction. As we know from school the angle of the incoming light will result to the angle of the reflected light when using a flat surface. We just put our lightsource relative to the reflective layer so that we reach an angle about 45 degree. The incoming light will bounce off and never reache the WiiMote which is placed directly underneath the reflective layer. Touching the layer will cause the surface to be bended so that the light will bounce in nearly every direction. The toucharea is now visible to our WiiMote because some lightrays beeing reflected to the WiiMote.&amp;lt;/p&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&amp;lt;p&amp;gt;&amp;lt;img src=&#34;http://jotschi.de/images/holo/lightbeams.png&#34; alt=&#34;Lightbeams&#34; /&amp;gt;&amp;lt;br /&amp;gt;
&amp;lt;img src=&#34;http://jotschi.de/images/holo/lightbeams2.png&#34; alt=&#34;Lightbeams2&#34; /&amp;gt;&amp;lt;/p&amp;gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Inflatable VR hemisphere</title>
      <link>http://jotschi.de/2008/01/21/inflatable-vr-hemisphere/</link>
      <pubDate>Mon, 21 Jan 2008 03:18:58 +0000</pubDate>
      
      <guid>http://jotschi.de/2008/01/21/inflatable-vr-hemisphere/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Using an inflatable hemisphere as base for a virtual reality cave is in my mind a very good idea because you don&amp;#8217;t need any structures that stabilize the cave and you might only need one beamer to get a full 360° view shown inside the cave. This is done by projecting the image from above the cave onto its material.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&amp;lt;a id=&#34;more&#34;&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;a id=&#34;more-107&#34;&amp;gt;&amp;lt;/a&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;The movie gives a brief impression of what iam talking:
{% youtube 3llN2gHXDC4 %}&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Virtual Reality Freedom</title>
      <link>http://jotschi.de/2008/01/20/virtual-reality-freedom/</link>
      <pubDate>Sun, 20 Jan 2008 22:29:49 +0000</pubDate>
      
      <guid>http://jotschi.de/2008/01/20/virtual-reality-freedom/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Using robotic features and neuronal sensors it should be possible to create a robot that react on movements to simulate movement while realy &#34;standing still&#34; on the ground. Combined with virtual retinal displays or cyber glasses you could realy move inside the virtual reality without controling the movements of your virtual reality avatar by buttons or something else.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;{% youtube 14C2bDrZr4I %}&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Fast Orientated Desktop Item Transfer</title>
      <link>http://jotschi.de/2007/07/27/fast-orientated-desktop-item-transfer/</link>
      <pubDate>Fri, 27 Jul 2007 01:25:37 +0000</pubDate>
      
      <guid>http://jotschi.de/2007/07/27/fast-orientated-desktop-item-transfer/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Wer kennt es nicht? Das nahezu alltägliche Problem.. Man sitzt an seinem Laptop und möchte eine Datei vom Desktop des Laptops auf seinen Desktop-PC verschieben. Sicher es gibt schon unzählige Techniken (FTP, unison, E-Mail, Samba) und ich möchte auch nicht das Rad komplett neu erfinden aber..&amp;lt;a id=&#34;more&#34;&amp;gt;&amp;lt;/a&amp;gt;&amp;lt;a id=&#34;more-81&#34;&amp;gt;&amp;lt;/a&amp;gt; wäre es nicht viel Interessanter und auch spannender man könnte einfach das gewählte Objekt auf dem Desktop nach links bzw. rechts zum Rand schieben und jenes Objekt würde dann auf dem Desktop des jeweiligen Rechners erscheinen. Markierungen am Rand des jeweiligen Desktops könnten Informationen darüber bieten in welcher Richtung sich der nächste erreichbare und auch öffentliche bzw. freigeschaltete Desktop befindet. Natürlich fehlt für diesen Fall allerdings Hardware, die heraus findet ob sich ein weiterer Rechner links oder rechts oder vor oder hinter dem aktuell betriebenen Rechner befindet. Die Idee kam mir da ich selbst viel mit Multihead arbeite und oft den Laptop auf dem Schreibtisch stehen habe. Datentransfer kann unter solchen Umständen etwas lästig werden.
Besonders aber im schulischen Umfeld oder bei Projektarbeiten könnte sich ein solches Verfahren durchaus als praktisch erweisen. Vielleicht ist aber auch einfach nur eine Spielerei. Über Sinn und Unsinn möge man ruhig streiten.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Nachtrag:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ich bin auf Synergy gestoßen. Hiermit ist es möglich Maus und Tastatur über das Netzwerk zu Sharen. Ein Synergy Server wird entsprechend der Rechnerplatzirung konfiguriert. Besitzt man Beispielsweise zwei Rechner, so ist es möglich mit der Maus des einen Rechners den anderen zu steuern indem man einfach mit der Maus je nach Konfiguration den Desktopbereich in einer Richtung verlässt und somit den Desktop des anderen Rechners erreicht.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Synergy ist unter Windows und Linux lauffähig.
Link: &amp;lt;a href=&#34;http://synergy2.sourceforge.net/&#34;&amp;gt;Synergy&amp;lt;/a&amp;gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Phantasinator</title>
      <link>http://jotschi.de/2007/03/31/phantasinator/</link>
      <pubDate>Sat, 31 Mar 2007 15:57:54 +0000</pubDate>
      
      <guid>http://jotschi.de/2007/03/31/phantasinator/</guid>
      <description>&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Der Phantasinator? Was mag das sein? Ein hochmodernes Gerät welches einem die tollsten Dinge vorgaukelt? Oder vielleicht ein neuer Superheld?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Nein, eigentlich ist es nur der Titel für diesen Blogeintrag.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Was soll man machen wenn einem die Ideen ausgehen? Was soll man tun wenn man schon glaubt alle Phantasie und Kreativität verloren zu haben?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ich habe zwei Methoden gefunden die einem in einem solchen Fall nützlich sein können.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&amp;lt;li&amp;gt;1. Methode&amp;lt;/li&amp;gt;
Bei dieser Methode verwenden wir 3D Studio Max oder jede andere 3D Software. Mit etwas Arbeit würde es sogar in Photoshop gehen. (ist aber nicht so praktisch)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Zuerst erstellst du einen Quader. Es könnte auch irgendein anderes beliebiges Objekt sein. Wichtig ist hierbei nur das es relativ viel Geometrie enthält, da diese nacher von Bedeutung ist.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&amp;lt;a href=&#34;http://jotschi.de/images/phantasinator/3dsmax_basis.png&#34; title=&#34;3D Studio Max #1&#34;&amp;gt;&amp;lt;img src=&#34;http://jotschi.de/images/phantasinator/3dsmax_basis.thumbnail.png&#34; alt=&#34;3D Studio Max #1&#34; /&amp;gt;&amp;lt;/a&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Jetzt erhält der Quader einen &#34;Noise Modifizer&#34; um die Geometrie zu stören. Hierbei muss man etwas experimentieren bis das gewünschte Ziel (siehe Bild) erreicht worden ist. Wichtig ist hierbei das die Geometrie animiert wird.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&amp;lt;a href=&#34;http://jotschi.de/images/phantasinator/3dsmax_chaos.png&#34; title=&#34;3D Studio Max #3&#34;&amp;gt;&amp;lt;img src=&#34;http://jotschi.de/images/phantasinator/3dsmax_chaos.thumbnail.png&#34; alt=&#34;3D Studio Max #3&#34; /&amp;gt;&amp;lt;/a&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Als nächstes musst du den Blur passend einstellen. Dazu einfach Rechtsklick auf dein Objekt und Eigenschaften auswählen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&amp;lt;a href=&#34;http://jotschi.de/images/phantasinator/3dsmax_blur.png&#34; title=&#34;3D Studio Max #2&#34;&amp;gt;&amp;lt;img src=&#34;http://jotschi.de/images/phantasinator/3dsmax_blur.thumbnail.png&#34; alt=&#34;3D Studio Max #2&#34; /&amp;gt;&amp;lt;/a&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Alles fertig? Dann empfiehlt es sich die komplette Sequenz in Einzelbildern herraus zu rendern. So kannst du später dir alle Bilder nach und nach anschauen und nach Strukturen etc. suchen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&amp;lt;a href=&#34;http://jotschi.de/images/phantasinator/2_m1.png&#34; title=&#34;Blur #2&#34;&amp;gt;&amp;lt;img src=&#34;http://jotschi.de/images/phantasinator/2_m1.thumbnail.png&#34; alt=&#34;Blur #2&#34; /&amp;gt;&amp;lt;/a&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&amp;lt;a href=&#34;http://jotschi.de/images/phantasinator/1_m1.png&#34; title=&#34;Blur #1&#34;&amp;gt;&amp;lt;img src=&#34;http://jotschi.de/images/phantasinator/1_m1.thumbnail.png&#34; alt=&#34;Blur #1&#34; /&amp;gt;&amp;lt;/a&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&amp;lt;a href=&#34;http://jotschi.de/images/phantasinator/3_komplex_m1.png&#34; title=&#34;Blur #4&#34;&amp;gt;&amp;lt;img src=&#34;http://jotschi.de/images/phantasinator/3_komplex_m1.thumbnail.png&#34; alt=&#34;Blur #4&#34; /&amp;gt;&amp;lt;/a&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Es bietet sich auch an das Objekt zu clonen und zu verschieben. Zusätzlich sollte aber auch die Animation angepasst werden.
&amp;lt;a href=&#34;http://jotschi.de/images/phantasinator/3_komplex_farbe_m1.png&#34; rel=&#34;attachment wp-att-34&#34; title=&#34;Blur #3&#34;&amp;gt;&amp;lt;img src=&#34;http://jotschi.de/images/phantasinator/3_komplex_farbe_m1.thumbnail.png&#34; alt=&#34;Blur #3&#34; /&amp;gt;&amp;lt;/a&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Je nach Farbe erhält man auch etwas düstere Bilder.
&amp;lt;a href=&#34;http://jotschi.de/images/phantasinator/xarlphibien.jpg&#34; title=&#34;Xarlphibien&#34;&amp;gt;&amp;lt;img src=&#34;http://jotschi.de/images/phantasinator/xarlphibien.thumbnail.jpg&#34; alt=&#34;Xarlphibien&#34; /&amp;gt;&amp;lt;/a&amp;gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&amp;lt;li&amp;gt;2. Methode&amp;lt;/li&amp;gt;
Alles was du bei dieser Methode brauchst sind ein paar Textmarker, etwas Papier, ein Scanner und ein Computer.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Zuerst schraffierst du ein wenig mit den Textmarkern auf dem Papier. Hier kannst du die Breite der Schraffur variieren. Wiederhol das ganze bist du ca vier bis fünf 4x4cm große interessante Strukturflächen hast. Diese Strukturen werden eingescannt und in Photoshop als Layer übereinander gelegt. Jetzt varrierst du solange die Überblendungsarten und stärke der Überlagerungen, sowie Kontrast der Layer und deren Position, bis du ein interessantes Bild erhälst. In diesem Bild kannst du nun nach verborgenen Strukturen suchen. Wenn du fündig geworden bist kannst du sie in Photoshop direkt weiter herrausarbeiten oder du druckst dir dein Bild aus und begibst dich mit &#34;per Hand&#34; ans Werk.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Alternativ kann ich euch auch zusätzlich nur noch das in die Wolken schauen ans Herz legen.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>