---
author: Jotschi
author_email: webmaster@jotschi.de
author_login: admin
author_url: http://www.Jotschi.de
categories:
- Uncategorized
comments:
- author: Scott Widmann
  author_email: scott.widmann@gmail.com
  author_url: ""
  content: |-
    Excellent work, are you still developing the project? I am a project manager for a construction company in the united states. For the past few years I have been focused on developing and implementing 3D methods for design and construction commonly termed (Building Information Modeling.) The models and textures you have created could be used to QC work in the field especially if they can be combined with panoramic photos of the interior to create complete models. Can your software create complete models of both the interior and the exterior walls and ceilings or have you found any others that can? I hope we have an opportunity to speak more, I believe there is an opportunity to develop a tool that has a significant impact on the design and construction industries.

    Sincerely,

    Scott Widmann
  date: 2012-09-26 22:10:04 +0000
  date_gmt: 2012-09-26 20:10:04 +0000
  id: 6704
- author: Jotschi
  author_email: webmaster@jotschi.de
  author_url: http://www.Jotschi.de
  content: "Unfortunately my time is very limited and the project ended when i determined
    that open scene graph is not flexible enough to deal with my requirements. I spend
    some time and investigated megatextures because this is in my mind a good approach
    to deal with very large textures/projection. Implementing a Megatexture/Sparse
    Voxel Octree is a very time consuming and complex Ã\NÂ§ask. \nI think the project
    itself is still important for me since some of my current projects (like the DIY
    HMD) are related to it. The software itself was only aimed at the texturing of
    external environments. Texturing of rooms etc. should also work with that approach.
    \nI don't know any software that is aimed on the creation of interior environments.
    Maybe <a href=\"http://phototour.cs.washington.edu/bundler/\" rel=\"nofollow\">bundler</a>
    or <a href=\"http://www.youtube.com/watch?v=bRgEdqDiOuQ\" rel=\"nofollow\">KinectFusion</a>
    would be worth a look."
  date: 2012-09-27 00:34:48 +0000
  date_gmt: 2012-09-26 22:34:48 +0000
  id: 6708
date: 2009-07-13T00:03:19Z
excerpt: "<del datetime=\"2012-09-26T22:09:41+00:00\">Currently i'm</del>Some time
  ago i was developing methods and software to transform panorama images into 3d models.
  The panorama image itself should be projected onto a generated 3d mesh. \nThis would
  generate a textured 3d model which could be used as key for the development of different
  applications. In this article i will describe my approach and show some perspectives
  for some applications."
published: true
status: publish
tags: []
title: Generating City Models By Using Panorama Images
url: /2009/07/13/generating-city-models-by-using-panorama-images/
wordpress_id: 320
wordpress_url: /?page_id=320
---

<del datetime="2012-09-26T22:09:41+00:00">Currently i'm</del>Some time ago i was developing methods and software to transform panorama images into 3d models. The panorama image itself should be projected onto a generated 3d mesh. 
This would generate a textured 3d model which could be used as key for the development of different applications. In this article i will describe my approach and show some perspectives for some applications.<a id="more"></a><a id="more-320"></a>
A slightly similar approach is done by <a href="http://interactive.usc.edu/viewfinder/">viewfinder</a> which enables the user to position the image into a 3D context.

<h1>Project Goals</h1>
<h2>Phase I goals:</h2>
<ul>
<li>Automatically creating a textured 3D city model.</li>
</ul>

== Phase II goals:

* Auto align any image that was taken within the area of the created city model.


== Phase III goals:

* Refine geometric data of the city model by using structure from motion techniques.


== Project Description
By using <a href="http://www.openstreetmap.org/">openstreetmap - OSM</a> data and basic computer vision edge detection of panorama images it is possible to find simple corrolating points between the panorama image and the openstreetmap data. The process is described below.

Developing a software that is capabel of transforming information gathered from panoramic images and geo location based map data into a world model. Further this world model can be used to extrapolate the position of a viewer by corolating template images from the world model view and the image that was taken from the view.

<a href="http://interactive.usc.edu/viewfinder/index.html">Viewfinder</a>

httpv://www.youtube.com/watch?v=3b8ACCN3wSw
This video shows the basic principle of projecting a panorama image onto 3d surfaces. This video is just a proof of concept that you can use openstreetmap data as a valid basis for the mesh generation. In my mind the accuracy is quite good. 


_Mesh generation:_

<a href="/images/osm3d/unmapped.png"><img src="/images/osm3d/unmapped.png" alt="" title="Panorama Simple" width="500" class="alignnone size-medium wp-image-336" /></a>
This is the panorama source image.


<a href="/images/osm3d/mapped_lines.png"><img src="/images/osm3d/mapped_lines.png" alt="" title="Panorama Mapped Lines" width="500" class="alignnone size-medium wp-image-335" /></a>
By using the initial camera position and orientation of the panorama image we can align the openstreet map data. The arrows in the image indicates the direction in which the facing surface will be generated.

<a href="/images/osm3d/edges.png"><img src="/images/osm3d/edges.png" alt="" title="Extracted edges" width="500"  class="alignnone size-medium 
wp-image-334" /></a>
The bottom end of the surface is defined by the openstreetmap data and the top end by the extracted contour.




_Map generation:_
To avoid generation of surfaces that can't be seen by the viewer we just remove all these lines in the osm map data as described here. At first we generate the normal vectors for each line to determine if the (bottom) line will be part of a facing surface.

<a href="/images/osm3d/3.png"><img src="/images/osm3d/3.png" alt="" title="3" width="500" class="alignnone size-medium wp-image-332" /></a>

We remove all lines that do not belong to a facing surface by comparing the view vector with the normal vector. 

<a href="/images/osm3d/2.png"><img src="/images/osm3d/2.png" alt="" title="2" width="500" class="alignnone size-medium wp-image-331" /></a>

After removing these lines we also remove the lines which are currently not visible by the viewer. This can be done by defining a 2d view volume. All lines that aren't visible will be removed.

<a href="/images/osm3d/4.png"><img src="/images/osm3d/4.png" alt="" title="4" width="500"  class="alignnone size-medium wp-image-333" /></a>

== Applications
Aligning any image with some parameters about its location precisely within this scene can open a variety of applications. Such as real time augmented reality applications. You can superimpose any content over an image or a video of the scene. And more specific: You could align your content to any surface the scene provides. Imagine arrows that point a direction along walls of a building.

== Development
Currently i'm developing the applications in cpp using OpenCV and OpenSceneGraph (OSG).

What i have done:

* Projective Textures using glsl shaders. 15.07.2009</li>
* Extracting horizon contour from images using OpenCV functions. - 19.07.2009
* Creating a view volume that represents the actual view of the 'projector' within the program. 06.07.2009
* Align the extracted into the view volume of the program so that the contour will be superimposed over the viewed scene. - 22.07.2009
* Transforming osm data coordinates to <a href="http://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system">UTM.</a> - 01.08.2009
* Combining mesh creation & osm data & projection of image data within one program. - 03.08.2009
* Extracting openstreetmap data via xml web api by using a adapted c library. - 03.08.2009
* Developing a fast algorithm for generating a homogeneous polygon mesh between two lines. - 09.08.2009


What needs to be done:

* Align a unknown image which was taken within the scene using <a href="http://en.wikipedia.org/wiki/Scale-invariant_feature_transform">sift template matching</a> as key technology.
* Handling multiple projection sources within one scene
* Useing accelerometer data from wiimote to match the viewer orientation within the scene
* Using GPS data to match the viewer position within the scene.
* Refining the viewer attitude (position, field of view, orientation) by examine external image feed


<script src="http://www.gliffy.com/diagramEmbed.js" type="text/javascript"> </script>
<script type="text/javascript"> gliffy_did = "1785581"; embedGliffy(); </script>

Screenshots:
<img src="/images/osm3d/pano1.png" alt="pano1" title="pano1" width="580" height="486" class="alignnone size-full wp-image-416" />

Here you can see the generated mesh of the MQ using openstreetmap data. A projection is applied as texture to the model.


<img src="/images/osm3d/pano2.png" alt="pano2" title="pano2" width="783" height="590" class="alignnone size-full wp-image-417" />

Here you can see one projection face. A full projection will consists of four projection planes. One for each direction. As you can see the projection is divided into smaller parts. This must be done to achieve maximum image resolution of the projection since the maximum texture resolution is 2048x2048.

<img src="/images/osm3d/pano3.png" alt="pano3" title="pano3" width="770" height="664" class="alignnone size-full wp-image-418" />

This is the projector view. 

== Credits

The panorama image was taken by Jan Zarnikov. <a href="http://www.viewat.org/?i=en&sec=pn&id_pn=3878">Panorama at www.viewat.org</a>

